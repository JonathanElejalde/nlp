{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"char_language_model.ipynb","provenance":[],"mount_file_id":"18j2CYzlVkh5xvVv4AVgeCnkXCdtQLXT_","authorship_tag":"ABX9TyMNjn6FBbrJmnjb/ScX/EES"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltEvDmQujeg0","executionInfo":{"status":"ok","timestamp":1607634634671,"user_tz":300,"elapsed":1067,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"cc3c7ad3-fa67-43a3-d46d-c9b45afad79a"},"source":["%cd /content/drive/My Drive/Colab Notebooks/nlp/apps/language_models"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/nlp/apps/language_models\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P9HgnNO5jtKl"},"source":["# What we need to do\r\n","\r\n","- You will start by converting a line of text into a tensor\r\n","- Then you will create a generator to feed data into the model\r\n","- You will train a neural network in order to predict the new set of characters of defined length.\r\n","- You will use embeddings for each character and feed them as inputs to your model.\r\n","    - Many natural language tasks rely on using embeddings for predictions.\r\n","\r\n","- Your model will convert each character to its embedding, run the embeddings through a Gated Recurrent Unit GRU, and run it through a linear layer to predict the next set of characters.\r\n","\r\n","- You will get the embeddings;\r\n","- Stack the embeddings on top of each other;\r\n","- Run them through two layers with a relu activation in the middle;\r\n","- Finally, you will compute the softmax. \r\n","\r\n","To predict the next character:\r\n","- Use the softmax output and identify the word with the highest probability.\r\n","- The word with the highest probability is the prediction for the next word."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkzpbTWrkQM4","executionInfo":{"status":"ok","timestamp":1607634644956,"user_tz":300,"elapsed":11340,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"38be7522-ca98-4140-c547-f982ac739661"},"source":["!pip install -q -U trax"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 471kB 13.6MB/s \n","\u001b[K     |████████████████████████████████| 2.6MB 55.6MB/s \n","\u001b[K     |████████████████████████████████| 174kB 62.1MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 59.3MB/s \n","\u001b[K     |████████████████████████████████| 71kB 11.9MB/s \n","\u001b[K     |████████████████████████████████| 3.7MB 50.7MB/s \n","\u001b[K     |████████████████████████████████| 1.4MB 49.0MB/s \n","\u001b[K     |████████████████████████████████| 348kB 51.2MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 50.3MB/s \n","\u001b[K     |████████████████████████████████| 890kB 32.4MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XD0hpHk5j4Ia","executionInfo":{"status":"ok","timestamp":1607634662510,"user_tz":300,"elapsed":28886,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"7328d80f-7bc0-4ffe-cc5f-20b255e36120"},"source":["import trax\r\n","import trax.fastmath.numpy as np\r\n","import numpy\r\n","import random\r\n","import itertools\r\n","from trax import fastmath"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"4e6K4mnBkvKo"},"source":["# Get the data\r\n","\r\n","We will treat the sherlock novels are our data. Then, we will treat each line as a sentence, because we are going to predict characters instead of words, we need to convert each sentence into characters. After this, each character line is going to be stored in a list. In other words, we are going to have a list of list of characters.       \r\n","Finally, we will create a generator that takes the batch_size and max_length. Where max_length is the sentence with the maximum size.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"cAn-L03Ykyv_","executionInfo":{"status":"ok","timestamp":1607634662514,"user_tz":300,"elapsed":28884,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["path = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/sherlock_novels.txt'\r\n","testing_path = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/study in scarlet.txt'\r\n","output_dir = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/language_models/models'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABPB3lsRmO8l","executionInfo":{"status":"ok","timestamp":1607634662516,"user_tz":300,"elapsed":28881,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def get_sentences(path):\r\n","    \"\"\"\r\n","    Reads a txt file and returns each line (sentence)\r\n","    in a list\r\n","    \"\"\"\r\n","    with open(path) as f:\r\n","        sentences = f.readlines()\r\n","\r\n","    return sentences\r\n","\r\n","def get_max_length(sentences):\r\n","    \"\"\"\r\n","    Takes a list of sentences and search for the\r\n","    longest one.\r\n","    \"\"\"\r\n","    sentence = max(sentences, key=len)\r\n","    max_length = len(sentence)\r\n","    return max_length, sentence\r\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIn0h4-6nMb5"},"source":["# Preprocess\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"J7OrKdZuoGW9","executionInfo":{"status":"ok","timestamp":1607634662519,"user_tz":300,"elapsed":28877,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def preprocess(sentences):\r\n","    \"\"\"\r\n","    Takes a list of sentences to clean and lowercase them\r\n","    \"\"\"\r\n","    for i, sentence in enumerate(sentences):\r\n","        sentences[i] = sentence.strip().lower()\r\n","\r\n","    return sentences\r\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g60CniXloGdx"},"source":["# Create validation and test set"]},{"cell_type":"code","metadata":{"id":"2DaNnMK4oGgz","executionInfo":{"status":"ok","timestamp":1607634662520,"user_tz":300,"elapsed":28873,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def create_train_val(sentences):\r\n","    \"\"\"\r\n","    It takes a list of sentences and divides them into\r\n","    90% train and 10% validation\r\n","    \"\"\"\r\n","    n = len(sentences)\r\n","    pct = int(n * 0.9)\r\n","    train = sentences[:pct]\r\n","    validation = sentences[pct:]\r\n","\r\n","    return train, validation"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EkLAoaGDqDuA"},"source":["# Convert sentences to tensors\r\n","\r\n","Now, we need to convert our sentences into numbers, thus we can feed them into our model."]},{"cell_type":"code","metadata":{"id":"baVdUjZiqDz0","executionInfo":{"status":"ok","timestamp":1607634662522,"user_tz":300,"elapsed":28870,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def sentence2tensor(sentence, end_token=1):\r\n","    \"\"\"\r\n","    It takes the sentence and transforms each\r\n","    character to a number\r\n","    \"\"\"\r\n","    tensor = [ord(char) for char in sentence]\r\n","    # append the end token to the sentence\r\n","    tensor.append(end_token)\r\n","\r\n","    return tensor\r\n","\r\n","    \r\n","    \r\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7UNU5sr0xxUQ"},"source":["# Generate batches\r\n","\r\n","We will convert our text sentences into numpy arrays and we will add padding to each sentence. This padding will be determine by the sentence with the max_length in our corpus.\r\n","\r\n","The batch is a tuple with three values: inputs, targets, mask. Mask will be 1 for all non-padding tokens."]},{"cell_type":"code","metadata":{"id":"93Md-_nLxxXa","executionInfo":{"status":"ok","timestamp":1607634662523,"user_tz":300,"elapsed":28867,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def generate_batch(batch_size, max_length, sentences, sentence2tensor=sentence2tensor, shuffle=True):\r\n","    \"\"\"\r\n","    It takes a list of sentences, \r\n","    \"\"\"\r\n","    index = 0\r\n","    current_batch = []\r\n","    num_sentences = len(sentences)\r\n","\r\n","    # create an array with the indexes of sentences that can be shuffled\r\n","    sentences_index = [*range(num_sentences)]\r\n","\r\n","    if shuffle:\r\n","        random.shuffle(sentences_index)\r\n","\r\n","    while True:\r\n","        if index >= num_sentences:\r\n","            # reset index if we used all the sentences\r\n","            index = 0\r\n","\r\n","            if shuffle:\r\n","                random.shuffle(sentences_index)\r\n","\r\n","        # get a sentence\r\n","        sentence = sentences[sentences_index[index]]\r\n","\r\n","        if len(sentence) < max_length:\r\n","            current_batch.append(sentence)\r\n","\r\n","        index += 1\r\n","\r\n","        # check if we already have our desire batch_size\r\n","        if len(current_batch) == batch_size:\r\n","            batch = []\r\n","            mask = []\r\n","            for batch_sentence in current_batch:\r\n","                # convert the batch sentence to a tensor\r\n","                tensor = sentence2tensor(batch_sentence)\r\n","\r\n","                # add the padding\r\n","                pad = [0] * (max_length - len(tensor))\r\n","                tensor_padded = tensor + pad\r\n","\r\n","                batch.append(tensor_padded)\r\n","                mask_tensor = [0 if i == 0 else 1 for i in tensor_padded]\r\n","                mask.append(mask_tensor)\r\n","\r\n","            # convert the padded tensor into a trax tensor\r\n","            trax_batch = np.array(batch)\r\n","            trax_mask = np.array(mask)\r\n","\r\n","            # yield two copies of the batch and mask\r\n","            yield trax_batch, trax_batch, trax_mask\r\n","\r\n","            # reset current_batch to an empty list\r\n","            current_batch = []\r\n","                \r\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZRtzOI_NIE8"},"source":["Once we have our function to generate batches, we need to a way to cycle over them and thus we create multiple epochs. One way to do it is with the itertools.cycle() function.\r\n","\r\n","```python\r\n","import itertools\r\n","\r\n","infinite_generator = itertools.cycle(generate_batch(batch_size, max_length, sentences))\r\n","```"]},{"cell_type":"markdown","metadata":{"id":"aD6KHbvvNIJF"},"source":["# Create the model"]},{"cell_type":"code","metadata":{"id":"vNrzOA8zNIMc","executionInfo":{"status":"ok","timestamp":1607634662524,"user_tz":300,"elapsed":28864,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def create_model(vocab_size=256, emb_dim=300, n_layers=2, mode='train'):\r\n","    \"\"\"\r\n","    Returns a GRU model.\r\n","    Args:\r\n","        vocab_size: int. the amount of unique char\r\n","        emb_dim: int. embeddings depth\r\n","        n_layers: int. number of GRU layers\r\n","        mode: str\r\n","    returns:\r\n","        model: a trax model\r\n","    \"\"\"\r\n","    model = trax.layers.Serial(\r\n","        trax.layers.ShiftRight(mode=mode),\r\n","        trax.layers.Embedding(vocab_size, emb_dim),\r\n","        [trax.layers.GRU(emb_dim) for _ in range(n_layers)],\r\n","        trax.layers.Dense(vocab_size),\r\n","        trax.layers.LogSoftmax()\r\n","    )\r\n","\r\n","    return model\r\n","\r\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DH1vABs_UT94"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"Cw3p6FbbUUBq","executionInfo":{"status":"ok","timestamp":1607634663156,"user_tz":300,"elapsed":29491,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["sentences = get_sentences(testing_path)\r\n","pre_sentences = preprocess(sentences)\r\n","# get_max_length returns the len and the sentence\r\n","max_length, _ = get_max_length(pre_sentences)\r\n","batch_size = 32\r\n","train, val = create_train_val(pre_sentences)\r\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"qPF72hubUUEz","executionInfo":{"status":"ok","timestamp":1607634663165,"user_tz":300,"elapsed":29496,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["# num_sentences = len(pre_sentences)\r\n","# print(num_sentences)\r\n","# print(int(num_sentences / batch_size))\r\n","\r\n","def train_model(model, train_sentences, val_sentences, generate_batch, \r\n","                max_lenght, learning_rate= 0.0001, batch_size=32, epochs=1, output_dir='models/'):\r\n","    \"\"\"\r\n","    It trains our trax model\r\n","    Args:\r\n","        model: trax model\r\n","        train_sentences: list\r\n","        val_sentences: list\r\n","        generate_batch: func\r\n","        max_length: int. it is the max length of the longest sentence\r\n","        batch_size: int\r\n","        epochs: int\r\n","        output_dir: str\r\n","    returns:\r\n","        a trax Training loop for the model.\r\n","    \"\"\"\r\n","    train_generator = generate_batch(batch_size, max_length, sentences)\r\n","    infinite_train_generator = itertools.cycle(train_generator)\r\n","\r\n","    val_generator = generate_batch(batch_size, max_length, val_sentences)\r\n","    infinite_val_generator = itertools.cycle(val_generator)\r\n","\r\n","    train_task = trax.supervised.training.TrainTask(\r\n","        labeled_data=infinite_train_generator,\r\n","        loss_layer=trax.layers.CrossEntropyLoss(),\r\n","        optimizer=trax.optimizers.Adam(learning_rate)\r\n","    )\r\n","\r\n","    val_task = trax.supervised.training.EvalTask(\r\n","        labeled_data=infinite_val_generator,\r\n","        metrics=[trax.layers.CrossEntropyLoss(), trax.layers.Accuracy()],\r\n","        n_eval_batches=3\r\n","    )\r\n","\r\n","    training_loop = trax.supervised.training.Loop(model, train_task, \r\n","                                                  eval_tasks=val_task, output_dir=output_dir)\r\n","    \r\n","    training_loop.run(n_steps=epochs)\r\n","\r\n","    return training_loop\r\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"183VhYORUUHk"},"source":["%%timeit\r\n","training_loop = train_model(create_model(), train, val, generate_batch, max_length, epochs=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bgZCbAxnGM7"},"source":["# sentences = get_sentences(path)\r\n","# # n_sen = len(sen)\r\n","# # print(f\"Number of sen: {n_sen}\")\r\n","# # print(f\"Sample line at position 0 {sen[0]}\")\r\n","# # print(f\"Sample line at position 1000 {sen[1000]}\")\r\n","\r\n","# sentences = preprocess(sentences)\r\n","# train, val = create_train_val(sentences)\r\n","# # print(len(train))\r\n","# # print(len(val))\r\n","\r\n","# tensor = sentence2tensor(train[1000])\r\n","# # print(tensor)\r\n","\r\n","# max_length, sen = get_max_length(sentences)\r\n","# print(max_length)\r\n","# print(sen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZYrCg5YmVx1W"},"source":[""],"execution_count":null,"outputs":[]}]}