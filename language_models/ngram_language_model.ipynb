{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ngram_language_model.ipynb","provenance":[],"mount_file_id":"1xZokeORwfxnvaeA_N8kgKZXQ9eBeGY0J","authorship_tag":"ABX9TyPRuMb/mcdt1icoMMxglus+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BNSa2BZykeA","executionInfo":{"status":"ok","timestamp":1607304176961,"user_tz":300,"elapsed":577,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"6cd57f72-bd73-480a-e121-6b602f50b405"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/nlp/apps"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/nlp/apps\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RfQKAwany2KX","executionInfo":{"status":"ok","timestamp":1607304218772,"user_tz":300,"elapsed":612,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["path = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/study in scarlet.txt'"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jGDtwcxnzAX1"},"source":["# Preprocessing the corpus\n","\n","These are the preprocessing steps that we are going to use:\n","\n","- lowercase the text\n","- remove special characters\n","- split text to list of sentences\n","- split sentences into list of words\n","\n","Notice that we will consider each line as a sentences for this language model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGp6_0EwzcVk","executionInfo":{"status":"ok","timestamp":1607304372909,"user_tz":300,"elapsed":1467,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"00b3b744-f318-454a-eb25-6e6f758dac37"},"source":["import nltk\n","import re\n","\n","nltk.download('punkt')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtqGETKzzfiF","executionInfo":{"status":"ok","timestamp":1607312664311,"user_tz":300,"elapsed":575,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"ca162c99-06c4-42bb-db53-eef5f8ef4ee8"},"source":["def remove_special(sentence):\n","    \"\"\"\n","    Takes a sentence and only keeps .?! and space\n","    as special characters.\n","    Args:\n","        sentence: str\n","    returns\n","        sentence: str. The full sentence cleaned of special characters\n","    \"\"\"\n","    sentence = re.sub(r'[^a-zA-Z0-9.?! ]+', '', sentence)\n","\n","    return sentence\n","\n","def get_text(path):\n","    \"\"\"\n","    It reads a txt file and returns a string with all the corpus\n","    Args:\n","        path: str\n","    returns:\n","        text: str\n","    \"\"\"\n","    with open(path) as f:\n","        text = f.read()\n","\n","    return text\n","\n","def get_sentences(text):\n","    \"\"\"\n","    Takes a whole text removes special characters and divides it by \\n\n","    then it returns a list of list with the sentences\n","    Args:\n","        text: str\n","    returns:\n","        sentences: list\n","    \"\"\"\n","    text = text.lower()\n","    sentences = text.split('\\n')\n","    # also removes any empty line\n","    sentences = [remove_special(sentence.strip()) for sentence in sentences if len(sentence) > 0]\n","\n","    return sentences\n","\n","# Uncomment to see the 10 first sentences\n","\n","# text = get_text(path)\n","# sentences = get_sentences(text)\n","# for s in sentences[:10]:\n","#     print(s)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["a study in scarlet\n","chapter i\n","mr. sherlock holmes\n","in the year 1878 i took my degree of doctor of medicine of the\n","university of london and proceeded to netley to go through the\n","course prescribed for surgeons in the army. having completed my\n","studies there i was duly attached to the fifth northumberland\n","fusiliers as assistant surgeon. the regiment was stationed in india\n","at the time and before i could join it the second afghan war had\n","broken out. on landing at bombay i learned that my corps had\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3k1oWSNSSYeN"},"source":[""],"execution_count":null,"outputs":[]}]}