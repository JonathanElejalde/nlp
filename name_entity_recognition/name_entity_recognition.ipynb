{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"name_entity_recognition.ipynb","provenance":[],"mount_file_id":"1-dRKJQlnholufpXyJ3rwtlMQiPRXEeoX","authorship_tag":"ABX9TyO8Ya7yJtla+JQe3vWrYfoS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5JrleVZoY7t","executionInfo":{"status":"ok","timestamp":1607718458142,"user_tz":300,"elapsed":800,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"d934cb30-ab76-48c0-f9ef-556ddab442ed"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/nlp/apps/name_entity_recognition"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/nlp/apps/name_entity_recognition\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FnDh_qHKoteC","executionInfo":{"status":"ok","timestamp":1607718458145,"user_tz":300,"elapsed":793,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["path = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/sherlock_novels.txt'\r\n","testing_path = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/study in scarlet.txt'\r\n","ner_path = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/ner_dataset.csv'\r\n","words_path = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/words.txt'\r\n","tags_path = '/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/tags.txt'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzlX2lH4o2DT","executionInfo":{"status":"ok","timestamp":1607718461851,"user_tz":300,"elapsed":4492,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["!pip install -q -U trax"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCpszR1QpHTs","executionInfo":{"status":"ok","timestamp":1607718483652,"user_tz":300,"elapsed":26286,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"676989d5-f00f-4f71-c09e-786c63ed5d2f"},"source":["import trax\r\n","import random\r\n","import pandas as pd\r\n","import numpy as np\r\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n","WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"iPV2vtOgwens"},"source":["# Get the data\r\n","\r\n","The columns of the dataset are:\r\n","\r\n","- The sentence number\r\n","- the word\r\n","- the part of speech of the word\r\n","- the tags\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"uiFPdXcnpP3q","executionInfo":{"status":"ok","timestamp":1607718484379,"user_tz":300,"elapsed":26862,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"6e86d235-7415-4709-e586-f5ae932b50fe"},"source":["df = pd.read_csv(ner_path, encoding='ISO-8859-1')\r\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"KWeshCmNwUqM"},"source":["# Preprocess\r\n","\r\n","We are going to create two files: one with the unique tags and one with the unique words \r\n"]},{"cell_type":"code","metadata":{"id":"PrttC0DfyeC3","executionInfo":{"status":"ok","timestamp":1607718484385,"user_tz":300,"elapsed":26855,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def create_vocab(df, path='/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/'):\r\n","    \"\"\"\r\n","    Takes the ner dataset and creates a txt file\r\n","    with words that appear at least once.\r\n","    \"\"\"\r\n","    # Lowercase and upercase are treated as different words\r\n","    counts = df.Word.value_counts()\r\n","\r\n","    # add the unknown and padding tokens\r\n","    words = list(counts.index) + ['UNK', '<pad>']\r\n","    with open(path + 'words.txt', 'w') as f:\r\n","        for word in words:\r\n","            f.write(word + '\\n')\r\n","\r\n","#create_vocab(df)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Phj62Ho0rcj","executionInfo":{"status":"ok","timestamp":1607718484388,"user_tz":300,"elapsed":26848,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def create_tags(df, path='/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/'):\r\n","    \"\"\"\r\n","    Takes the ner dataset and create a txt file with\r\n","    the different tags\r\n","    \"\"\"\r\n","    tags = list(df.Tag.value_counts().index)\r\n","    with open(path + 'tags.txt', 'w') as f:\r\n","        for tag in tags:\r\n","            if tag == 'O':\r\n","                continue\r\n","            f.write(tag + '\\n')\r\n","\r\n","#create_tags(df)\r\n","        \r\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZuIsk-YdU8J0","executionInfo":{"status":"ok","timestamp":1607718484390,"user_tz":300,"elapsed":26842,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def get_sentences_labels(df, path='/content/drive/MyDrive/Colab Notebooks/nlp/apps/data/'):\r\n","    \"\"\"\r\n","    Takes the ner dataset and extract the sentences\r\n","    and the labels to their respective txt file\r\n","    \"\"\"\r\n","    df_copy = df.copy()\r\n","    # Fill the na values with the sentence #\r\n","    df_copy.fillna(method='ffill', inplace=True)\r\n","\r\n","    # Store the unique sentences in a list\r\n","    sentences = list(df_copy['Sentence #'].unique())\r\n","    df_copy.set_index('Sentence #', drop=True, inplace=True)\r\n","\r\n","    # with the Sentence # column as index is easier to iterate\r\n","    # to get the individual sentences\r\n","    str_sentences = []\r\n","    labels = []\r\n","    print(f'Amount of sentences to process: {len(sentences)}')\r\n","    for i, sentence in enumerate(sentences):\r\n","        try:\r\n","            # get the individual words\r\n","            words = df_copy.loc[sentence].Word.values\r\n","\r\n","            \r\n","            # get the individual labels\r\n","            ind_labels = df_copy.loc[sentence].Tag.values\r\n","\r\n","            # Join the words and ind_labels in their\r\n","            # respective string\r\n","            str_sentence = ' '.join(words)\r\n","            label = ' '.join(ind_labels)\r\n","            str_sentences.append(str_sentence)\r\n","            labels.append(label)\r\n","\r\n","            if i % 500 == 0:\r\n","                print(f'{i} sentences processed')\r\n","        except Exception as e:\r\n","            print(e)\r\n","            print(f'Error in sentence {i}')\r\n","\r\n","\r\n","    # Save the str_sentences and labels into individual\r\n","    # txt files\r\n","    print('----Saving sentences----')\r\n","    with open(path + 'sentences.txt', 'w') as f:\r\n","        for sentence in str_sentences:\r\n","            f.write(sentence + '\\n')\r\n","    print('----Saving labels----')\r\n","    with open(path + 'labels.txt', 'w') as f:\r\n","        for label in labels:\r\n","            f.write(label + '\\n')\r\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ye65yTwIU8P3","executionInfo":{"status":"ok","timestamp":1607720797143,"user_tz":300,"elapsed":2339578,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}},"outputId":"6c3fa86e-a705-43a6-9c45-596666822bcf"},"source":["get_sentences_labels(df)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Amount of sentences to process: 47959\n","0 sentences processed\n","500 sentences processed\n","1000 sentences processed\n","1500 sentences processed\n","2000 sentences processed\n","2500 sentences processed\n","3000 sentences processed\n","3500 sentences processed\n","4000 sentences processed\n","4500 sentences processed\n","5000 sentences processed\n","5500 sentences processed\n","6000 sentences processed\n","6500 sentences processed\n","7000 sentences processed\n","7500 sentences processed\n","8000 sentences processed\n","'str' object has no attribute 'values'\n","Error in sentence 8411\n","8500 sentences processed\n","9000 sentences processed\n","9500 sentences processed\n","10000 sentences processed\n","10500 sentences processed\n","11000 sentences processed\n","11500 sentences processed\n","12000 sentences processed\n","12500 sentences processed\n","13000 sentences processed\n","13500 sentences processed\n","14000 sentences processed\n","14500 sentences processed\n","15000 sentences processed\n","15500 sentences processed\n","16000 sentences processed\n","16500 sentences processed\n","17000 sentences processed\n","17500 sentences processed\n","18000 sentences processed\n","18500 sentences processed\n","19000 sentences processed\n","19500 sentences processed\n","20000 sentences processed\n","20500 sentences processed\n","21000 sentences processed\n","21500 sentences processed\n","22000 sentences processed\n","22500 sentences processed\n","23000 sentences processed\n","23500 sentences processed\n","24000 sentences processed\n","24500 sentences processed\n","25000 sentences processed\n","25500 sentences processed\n","26000 sentences processed\n","26500 sentences processed\n","27000 sentences processed\n","27500 sentences processed\n","28000 sentences processed\n","28500 sentences processed\n","29000 sentences processed\n","29500 sentences processed\n","30000 sentences processed\n","30500 sentences processed\n","31000 sentences processed\n","31500 sentences processed\n","32000 sentences processed\n","32500 sentences processed\n","33000 sentences processed\n","33500 sentences processed\n","34000 sentences processed\n","34500 sentences processed\n","35000 sentences processed\n","35500 sentences processed\n","36000 sentences processed\n","36500 sentences processed\n","37000 sentences processed\n","37500 sentences processed\n","38000 sentences processed\n","38500 sentences processed\n","'str' object has no attribute 'values'\n","Error in sentence 38916\n","39000 sentences processed\n","39500 sentences processed\n","40000 sentences processed\n","40500 sentences processed\n","41000 sentences processed\n","41500 sentences processed\n","42000 sentences processed\n","42500 sentences processed\n","43000 sentences processed\n","43500 sentences processed\n","44000 sentences processed\n","44500 sentences processed\n","45000 sentences processed\n","45500 sentences processed\n","46000 sentences processed\n","46500 sentences processed\n","47000 sentences processed\n","47500 sentences processed\n","----Saving sentences----\n","----Saving labels----\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kgE1W4s_U8Sb","executionInfo":{"status":"ok","timestamp":1607720797148,"user_tz":300,"elapsed":2339579,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":[""],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jVxy8Gdn1Wxh"},"source":["once we have our tags and words, we need to map them into numbers that we can fit in our model.\r\n"]},{"cell_type":"code","metadata":{"id":"KwIXfwADOUyW","executionInfo":{"status":"ok","timestamp":1607720797152,"user_tz":300,"elapsed":2339575,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["def words_tags2index(words_path, tags_path):\r\n","    \"\"\"\r\n","    Takes the words.txt and tags.txt files and \r\n","    returns a dict mapping each word and token to\r\n","    a number\r\n","    \"\"\"\r\n","    word_map = dict()\r\n","    tag_map = dict()\r\n","    with open(words_path) as f:\r\n","        for i, word in enumerate(f.readlines(), 1):\r\n","            word_map[word.strip()] = i\r\n","    \r\n","    with open(tags_path) as f:\r\n","        for i, tag in enumerate(f.readlines(), 1):\r\n","            tag_map[tag.strip()] = i\r\n","    \r\n","    # set the O tag to 0\r\n","    tag_map['O'] = 0\r\n","    \r\n","    return word_map, tag_map\r\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"mINqyoEPPhjs","executionInfo":{"status":"ok","timestamp":1607720797165,"user_tz":300,"elapsed":2339583,"user":{"displayName":"Jonathan David Elejalde Gutiérrez","photoUrl":"","userId":"11854874717100226645"}}},"source":["word_map, tag_map = words_tags2index(words_path, tags_path)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Vw4KAlTSVpP"},"source":["# Understanding the tags\r\n","\r\n","The tag_map corresponds to one of the possible tags a word can have. The prepositions in the tags mean:\r\n","* I: Token is inside an entity.\r\n","* B: Token begins an entity."]}]}